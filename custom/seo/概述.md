## 1.搜索引擎优化
1.搜索引擎网站的后台会有一个非常庞大的数据库，里面存储着海量的关键词，关键词对应着很多网站
2.搜索引擎的网络爬虫算法或者代码，每天下载分析各种网站，从一个链接到另一个链接。进行分析，并找到其中的关键词。在这个寻找过程中，会存储数据库中没有的，但是对用户有用的。否则就舍弃不要。
3.一般来说，一个关键词对应多个网站，因此出现了排序的问题。相关程度高的就会出现在最前面。蜘蛛算法
无法识别flash和js，。为了能够让网站内容可以被搜索引擎识别，提高网站的权重，增加对该网站的友好度，这样的一个过程就是seo。
4.
## seo优化方式
1.title，description，keywords
2.语义化的标签
3.非装饰性的必须加上alt
4.让重要的内容放置在最前面，优先加载，因为搜索引擎算法抓取顺序是从上到下，保证内容一定被抓取
5.每个页面只有一个h1标签
6.少用iframe，iframe抓取不到
7.尽量不要做成flash，图片视屏
8.页面尽量扁平，嵌套太深不好
9.异步ajax也无法抓取
10.采用友情链接
11.做好404页面

12控制链接数量
13.优化导航，进来的使用文字，img要加alt和title，加上面包屑导航
14.页面头部和底部和page
15.重要的信息放在最前面
16.控制页面的大小，减少http请求

## 2.网页代码优化
1.title：强调重点，关键词不要重复出现，尽量做到每个页面的title不设置相同的内容
2.keywords关键词，列出关键字即可，切记过分堆砌
3.高度概括，不能太长，每个页面不同
4.语义化标签
5. 《a》 加上title说明，如果是外部链接，就要使用nofollow，禁止爬取
6.h1 不能过分使用
7.img加上alt
8.表格使用caption
9.<strong>><em>,b和i不会起到任何作用
10.重要的内容不要使用js输出，vue的seo缺陷，使用ssr
11.少使用iframe
12.会过滤到display：none的内容
13只能爬取a中的href，url后面最好不要带参数

## 14.robots.txt
告诉网络蜘蛛，哪些是可以爬取的，哪些是不可以被爬取的，它并不是一个规范，只是一个约定协议，并不能保护网站的隐私
1.存放在网站根目录下，